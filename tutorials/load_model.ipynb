{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6336aa47-e070-4ea8-86c9-bee95fc47816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First download the models\n",
    "\n",
    "# !python ../download_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d192d955-51eb-41c5-b369-ab79e2c6b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from pytorch_beam_search import seq2seq\n",
    "from post_ocr_correction import correction\n",
    "import re\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b5d6d0c-873f-4e51-9fd5-76843e8d4b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vocabularies and model, in this case, we are loading\n",
    "# the english model\n",
    "\n",
    "with open(\"data/models/en/model_en.arch\", \"rb\") as file:\n",
    "    architecture = pickle.load(file)\n",
    "source = list(architecture[\"in_vocabulary\"].keys())\n",
    "target = list(architecture[\"out_vocabulary\"].values())\n",
    "source_index = seq2seq.Index(source)\n",
    "target_index = seq2seq.Index(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5770372f-d1cc-4617-bc24-93f93bc2432f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Seq2Seq Transformer\n",
      "Source index: <Seq2Seq Index with 164 items>\n",
      "Target index: <Seq2Seq Index with 164 items>\n",
      "Max sequence length: 110\n",
      "Embedding dimension: 256\n",
      "Feedforward dimension: 1024\n",
      "Encoder layers: 2\n",
      "Decoder layers: 2\n",
      "Attention heads: 8\n",
      "Activation: relu\n",
      "Dropout: 0.5\n",
      "Trainable parameters: 3,841,700\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jarobyte/anaconda3/envs/poc/lib/python3.11/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# remove keys from old API of pytorch_beam_search\n",
    "\n",
    "for k in [\n",
    "   \"in_vocabulary\",\n",
    "   \"out_vocabulary\",\n",
    "   \"model\",\n",
    "   \"parameters\"\n",
    "]:\n",
    "    architecture.pop(k)\n",
    "model = seq2seq.Transformer(source_index, target_index, **architecture)\n",
    "state_dict = torch.load(\n",
    "    \"data/models/en/model_en.pt\",\n",
    "    map_location = torch.device(\"cpu\") # comment this line if you have a GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "638917e7-3009-4cbd-b663-15ba61b2de08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (source_embeddings): Embedding(164, 256)\n",
       "  (target_embeddings): Embedding(164, 256)\n",
       "  (positional_embeddings): Embedding(110, 256)\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.5, inplace=False)\n",
       "          (dropout2): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.5, inplace=False)\n",
       "          (dropout2): Dropout(p=0.5, inplace=False)\n",
       "          (dropout3): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=256, out_features=164, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change names from old API of pytorch_beam_search\n",
    "\n",
    "state_dict[\"source_embeddings.weight\"] = state_dict.pop(\"in_embeddings.weight\")\n",
    "state_dict[\"target_embeddings.weight\"] = state_dict.pop(\"out_embeddings.weight\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfa4f7fe-0bf9-4d90-9c4e-4b528ace432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "\n",
    "test = \"th1s 1s a c0rrupted str1ng\"\n",
    "reference = \"this is a corrupted string\"\n",
    "new_source = [list(test)]\n",
    "X_new = source_index.text2tensor(new_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "808478fd-0f8d-4468-b12b-6e09eb110232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plain beam search\n",
    "\n",
    "predictions, log_probabilities = seq2seq.beam_search(\n",
    "    model, \n",
    "    X_new,\n",
    "    progress_bar = 0)\n",
    "just_beam = target_index.tensor2text(predictions[:, 0, :])[0]\n",
    "just_beam = re.sub(r\"<START>|<PAD>|<UNK>|<END>.*\", \"\", just_beam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "722445f7-0e31-4226-beb9-e21400f143ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post ocr correction\n",
    "\n",
    "disjoint_beam= correction.disjoint(\n",
    "    test,\n",
    "    model,\n",
    "    source_index,\n",
    "    target_index,\n",
    "    5,\n",
    "    \"beam_search\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a87a2119-a587-431d-b1b8-6e5c529936ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes, n_grams_beam = correction.n_grams(\n",
    "    test,\n",
    "    model,\n",
    "    source_index,\n",
    "    target_index,\n",
    "    5,\n",
    "    \"beam_search\",\n",
    "    \"triangle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c9c60b3-54c8-400d-ac52-d5bdaac177be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating all methods...\n",
      "  disjoint window...\n",
      "    greedy_search...\n",
      "    beam_search...\n",
      "  sliding\n",
      "    greedy...\n",
      "      uniform...\n",
      "      triangle...\n",
      "      bell...\n",
      "    beam...\n",
      "      uniform...\n",
      "      triangle...\n",
      "      bell...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation = correction.full_evaluation(\n",
    "    [test],\n",
    "    [reference],\n",
    "    model,\n",
    "    source_index,\n",
    "    target_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98fe1632-1be4-44cd-bf8d-d10f0a48ed76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results\n",
      "  reference                       this is a corrupted string\n",
      "  test data                       th1s 1s a c0rrupted str1ng\n",
      "  plain beam search               this Is a corrupted \n",
      "  disjoint windows, beam search   this 1s a corrupted string. 1.\n",
      "  n-grams, beam search, triangle  this 1s a corrupted string\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window</th>\n",
       "      <th>decoding</th>\n",
       "      <th>window_size</th>\n",
       "      <th>weighting</th>\n",
       "      <th>inference_seconds</th>\n",
       "      <th>cer_before</th>\n",
       "      <th>cer_after</th>\n",
       "      <th>improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disjoint</td>\n",
       "      <td>greedy</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.098444</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>19.230769</td>\n",
       "      <td>-25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disjoint</td>\n",
       "      <td>greedy</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.167863</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>57.692308</td>\n",
       "      <td>-275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disjoint</td>\n",
       "      <td>beam</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.131956</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>19.230769</td>\n",
       "      <td>-25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disjoint</td>\n",
       "      <td>beam</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.312966</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>57.692308</td>\n",
       "      <td>-275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sliding</td>\n",
       "      <td>greedy</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.143648</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sliding</td>\n",
       "      <td>greedy</td>\n",
       "      <td>10</td>\n",
       "      <td>triangle</td>\n",
       "      <td>0.146170</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sliding</td>\n",
       "      <td>greedy</td>\n",
       "      <td>10</td>\n",
       "      <td>bell</td>\n",
       "      <td>0.144272</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sliding</td>\n",
       "      <td>beam</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.594327</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sliding</td>\n",
       "      <td>beam</td>\n",
       "      <td>10</td>\n",
       "      <td>triangle</td>\n",
       "      <td>0.607380</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sliding</td>\n",
       "      <td>beam</td>\n",
       "      <td>10</td>\n",
       "      <td>bell</td>\n",
       "      <td>0.752322</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     window decoding  window_size weighting  inference_seconds  cer_before  \\\n",
       "0  disjoint   greedy           20      <NA>           0.098444   15.384615   \n",
       "1  disjoint   greedy           10      <NA>           0.167863   15.384615   \n",
       "2  disjoint     beam           20      <NA>           0.131956   15.384615   \n",
       "3  disjoint     beam           10      <NA>           0.312966   15.384615   \n",
       "4   sliding   greedy           10   uniform           0.143648   15.384615   \n",
       "5   sliding   greedy           10  triangle           0.146170   15.384615   \n",
       "6   sliding   greedy           10      bell           0.144272   15.384615   \n",
       "7   sliding     beam           10   uniform           0.594327   15.384615   \n",
       "8   sliding     beam           10  triangle           0.607380   15.384615   \n",
       "9   sliding     beam           10      bell           0.752322   15.384615   \n",
       "\n",
       "   cer_after  improvement  \n",
       "0  19.230769        -25.0  \n",
       "1  57.692308       -275.0  \n",
       "2  19.230769        -25.0  \n",
       "3  57.692308       -275.0  \n",
       "4   3.846154         75.0  \n",
       "5   3.846154         75.0  \n",
       "6   3.846154         75.0  \n",
       "7   3.846154         75.0  \n",
       "8   3.846154         75.0  \n",
       "9   3.846154         75.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"results\")\n",
    "print(\"  reference                      \", reference)\n",
    "print(\"  test data                      \", test)\n",
    "print(\"  plain beam search              \", just_beam)\n",
    "print(\"  disjoint windows, beam search  \", disjoint_beam)\n",
    "print(\"  n-grams, beam search, triangle \", n_grams_beam)\n",
    "print()\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7d31a9-be05-4ce8-97dd-69872177ec62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
